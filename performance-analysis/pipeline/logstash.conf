input {
  tcp {
    port => 5044
    codec => json_lines
  }
}

filter {
  # No need for @metadata pipeline logic as there is no clear usage defined
  # Assuming we are just processing JSON logs from Spring Boot

  # Example of parsing Spring Boot logs assuming JSON format
  json {
    source => "message"
    remove_field => ["message"]
  }

  # Parse timestamp if it's in a specific format
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
    remove_field => ["timestamp"]
  }

  # Example: Adding custom fields for better indexing
  mutate {
    add_field => {
      "service_name" => "spring-boot-app"
      "environment" => "production"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["host", "path"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "spring-boot-logs-%{+YYYY.MM.dd}"
    # Optional: Set custom document type, e.g., "_doc"
    # document_type => "_doc"
  }
  stdout {
    codec => rubydebug
  }
}