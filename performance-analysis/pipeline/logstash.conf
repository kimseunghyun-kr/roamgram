input {
  tcp {
    port => 5044
    codec => json_lines;
  }
}

filter {
  if [@metadata][pipeline] {
    pipeline { address => [@metadata][pipeline];}
  }

  # Example of parsing Spring Boot logs assuming JSON format
  json {
    source => "message"
    remove_field => ["message"];
  }

  # Parse timestamp if it's in a specific format
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
    remove_field => ["timestamp"];
  }

  # Example: Adding custom fields for better indexing
  mutate {
    add_field => {
      "service_name" => "spring-boot-app"
      "environment" => "production";
    }
  }

  # Grok filter for additional parsing, if needed
  # Example: Parsing custom log patterns
  # grok {
  #   match => { "message" => "%{PATTERN}" }
  #   remove_field => ["message"]
  # }

  # Remove unnecessary fields
  mutate {
    remove_field => ["host", "path"];
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "spring-boot-logs-%{+YYYY.MM.dd}";
    # Optional: Set custom document type, e.g., "_doc"
    # document_type => "_doc"
  }
  stdout {
    codec => rubydebug;
  }
}
